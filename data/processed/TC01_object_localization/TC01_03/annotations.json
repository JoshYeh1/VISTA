{
  "annotations": [
    {
      "scene_image": "images/TC01_03_0000.jpg",
      "timestamp_ns": 17859419987850,
      "imu_row": 65,
      "audio_file": "audio.wav",
      "id": "TC01_03",
      "dataset_version": 1.0,
      "collection_date": "2025-07-01",
      "fps": 10,
      "camera_resolution": [
        1408,
        1408
      ],
      "test_case": "Object Location",
      "setup_description": "A table in an office with scattered objects on the surface: water bottle, laptop, wallet, phone, remote.",
      "user_query": "Where is my laptop?",
      "descriptive_ground_truth": "Your laptop is on the table infront of you. The screen is facing away from you.",
      "action_ground_truth": "Walk a step forwards and reach infront of you to close your laptop.",
      "task_type": null,
      "environment": "indoor",
      "lighting": "fluorescent",
      "distance_to_target": 0.89,
      "model_description_output": null,
      "model_action_output": null,
      "description_score": null,
      "action_score": null,
      "evaluation_method": null,
      "measurable_result": "location accuracy and spatial reference",
      "human_score": {
        "description_accuracy": null,
        "action_usefulness": null,
        "confidence": null
      }
    },
    {
      "scene_image": "images/TC01_03_0028.jpg",
      "timestamp_ns": 17862219993637,
      "imu_row": 2328,
      "audio_file": "audio.wav",
      "id": "TC01_03",
      "dataset_version": 1.0,
      "collection_date": "2025-07-01",
      "fps": 10,
      "camera_resolution": [
        1408,
        1408
      ],
      "test_case": "Object Location",
      "setup_description": "A table in an office with scattered objects on the surface: water bottle, laptop, wallet, phone, remote.",
      "user_query": "Where is my laptop?",
      "descriptive_ground_truth": "Your laptop is on the table infront of you. The screen is facing away from you.",
      "action_ground_truth": "Walk a step forwards and reach infront of you to close your laptop.",
      "task_type": null,
      "environment": "indoor",
      "lighting": "fluorescent",
      "distance_to_target": 0.89,
      "model_description_output": null,
      "model_action_output": null,
      "description_score": null,
      "action_score": null,
      "evaluation_method": null,
      "measurable_result": "location accuracy and spatial reference",
      "human_score": {
        "description_accuracy": null,
        "action_usefulness": null,
        "confidence": null
      }
    },
    {
      "scene_image": "images/TC01_03_0056.jpg",
      "timestamp_ns": 17865019987887,
      "imu_row": 4591,
      "audio_file": "audio.wav",
      "id": "TC01_03",
      "dataset_version": 1.0,
      "collection_date": "2025-07-01",
      "fps": 10,
      "camera_resolution": [
        1408,
        1408
      ],
      "test_case": "Object Location",
      "setup_description": "A table in an office with scattered objects on the surface: water bottle, laptop, wallet, phone, remote.",
      "user_query": "Where is my laptop?",
      "descriptive_ground_truth": "Your laptop is on the table infront of you. The screen is facing away from you.",
      "action_ground_truth": "Walk a step forwards and reach infront of you to close your laptop.",
      "task_type": null,
      "environment": "indoor",
      "lighting": "fluorescent",
      "distance_to_target": 0.89,
      "model_description_output": null,
      "model_action_output": null,
      "description_score": null,
      "action_score": null,
      "evaluation_method": null,
      "measurable_result": "location accuracy and spatial reference",
      "human_score": {
        "description_accuracy": null,
        "action_usefulness": null,
        "confidence": null
      }
    },
    {
      "scene_image": "images/TC01_03_0084.jpg",
      "timestamp_ns": 17867819989850,
      "imu_row": 6854,
      "audio_file": "audio.wav",
      "id": "TC01_03",
      "dataset_version": 1.0,
      "collection_date": "2025-07-01",
      "fps": 10,
      "camera_resolution": [
        1408,
        1408
      ],
      "test_case": "Object Location",
      "setup_description": "A table in an office with scattered objects on the surface: water bottle, laptop, wallet, phone, remote.",
      "user_query": "Where is my laptop?",
      "descriptive_ground_truth": "Your laptop is on the table infront of you. The screen is facing away from you.",
      "action_ground_truth": "Walk a step forwards and reach infront of you to close your laptop.",
      "task_type": null,
      "environment": "indoor",
      "lighting": "fluorescent",
      "distance_to_target": 0.89,
      "model_description_output": null,
      "model_action_output": null,
      "description_score": null,
      "action_score": null,
      "evaluation_method": null,
      "measurable_result": "location accuracy and spatial reference",
      "human_score": {
        "description_accuracy": null,
        "action_usefulness": null,
        "confidence": null
      }
    },
    {
      "scene_image": "images/TC01_03_0112.jpg",
      "timestamp_ns": 17870619988012,
      "imu_row": 9117,
      "audio_file": "audio.wav",
      "id": "TC01_03",
      "dataset_version": 1.0,
      "collection_date": "2025-07-01",
      "fps": 10,
      "camera_resolution": [
        1408,
        1408
      ],
      "test_case": "Object Location",
      "setup_description": "A table in an office with scattered objects on the surface: water bottle, laptop, wallet, phone, remote.",
      "user_query": "Where is my laptop?",
      "descriptive_ground_truth": "Your laptop is on the table infront of you. The screen is facing away from you.",
      "action_ground_truth": "Walk a step forwards and reach infront of you to close your laptop.",
      "task_type": null,
      "environment": "indoor",
      "lighting": "fluorescent",
      "distance_to_target": 0.89,
      "model_description_output": null,
      "model_action_output": null,
      "description_score": null,
      "action_score": null,
      "evaluation_method": null,
      "measurable_result": "location accuracy and spatial reference",
      "human_score": {
        "description_accuracy": null,
        "action_usefulness": null,
        "confidence": null
      }
    }
  ]
}